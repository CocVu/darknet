[net]
# Testing
# batch=64
# subdivisions=8
# Training
batch=64
subdivisions=2
# width=416
# height=416
width=128
height=128
channels=3
momentum=0.9
# momentum=0.95
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

# learning_rate=0.005
learning_rate=0.001
burn_in=1000
# max_batches = 10000
max_batches = 500200
policy=steps
steps=10000,900000
scales=.1,.1

# 0 conv 1
[convolutional]
batch_normalize=1
filters=8
size=5
stride=1
pad=1
activation=leaky

# 1 maxpool
[maxpool]
size=2
stride=2

# 2 conv
[convolutional]
batch_normalize=1
filters=8
size=3
stride=2
pad=1
activation=leaky

# 3 maxpool
[maxpool]
size=2
stride=2

# 4 conv
[convolutional]
batch_normalize=1
filters=16
size=5
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=5
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=5
stride=2
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=5
stride=2
pad=1
activation=leaky

[maxpool]
size=2
stride=1

# [convolutional]
# batch_normalize=1
# filters=1024
# size=3
# stride=1
# pad=1
# activation=leaky

###########

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=5
stride=2
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=30
activation=linear

[yolo]
mask = 3,4,5
anchors = 31,43, 38,76, 72,64, 82,103, 105,112
classes=5
num=6
jitter=.5
ignore_thresh = .5
truth_thresh = 1
random=0

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 8

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=30
activation=linear

[yolo]
mask = 1,2,3
anchors = 31,43, 38,76, 72,64, 82,103, 105,112
classes=5
num=6
jitter=.5
ignore_thresh = .5
truth_thresh = 1
random=0